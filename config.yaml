# Model Configuration
model:
  name: "llama3.2:3b"
  temperature: 0.7
  top_p: 0.9
  max_tokens: 2048
  repeat_penalty: 1.1
  context_window: 4096

# RAG Configuration
rag:
  chunk_size: 500
  chunk_overlap: 50
  similarity_threshold: 0.7
  max_retrieved_docs: 5
  embedding_model: "all-MiniLM-L6-v2"

# Vector Database Configuration
vectordb:
  persist_directory: "./data/chroma_db"
  collection_name: "knowledge_base"

# Application Settings
app:
  interface: "cli"  # Options: cli, web
  web_port: 8501
  debug: false

# Knowledge Base Settings
knowledge:
  base_directory: "./knowledge_base"
  supported_formats: [".txt", ".md", ".pdf"]
  auto_ingest: true
